{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3999087",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI, AzureChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "def design_synthesis(api_key: str,\n",
    "                      synthesis_text: str,\n",
    "                      azure: bool = True, \n",
    "                      model_name: str=None,\n",
    "                      temp: float=0,\n",
    "                      azure_api_version: str=None,\n",
    "                      azure_endpoint: str=None) -> str:\n",
    "    \"\"\"\n",
    "    Extract synthesis procedure from a given text.\n",
    "\n",
    "    Parameters:\n",
    "        api_key (str): OpenAI API key.\n",
    "        synthesis_text (str): The text containing synthesis information.\n",
    "        azure (bool): Flag to indicate if Azure OpenAI service should be used.\n",
    "        model_name (str, optional): The name of the Azure deployment or openai model name. Defaults to None.\n",
    "        temp (float, optional): The temperature for the model. Defaults to 0.\n",
    "        azure_api_version (str, optional): The API version for Azure OpenAI service. Defaults to None.\n",
    "        azure_endpoint (str, optional): The endpoint for Azure OpenAI service. Defaults to None.\n",
    "        \n",
    "    Returns:\n",
    "        str: JSON string containing the extracted synthesis procedure.\n",
    "    \"\"\"\n",
    "    if not azure:\n",
    "        llm = ChatOpenAI(model_name=model_name or os.getenv(\"OPENAI_MODEL_NAME\"),  # Replace with your OpenAI model name\n",
    "                         temperature=temp, \n",
    "                         openai_api_key=api_key or os.getenv(\"OPENAI_API_KEY\"))\n",
    "    else:\n",
    "        llm = AzureChatOpenAI(\n",
    "            azure_deployment=model_name or os.getenv(\"AZURE_MODEL_DEPLOYMENT_NAME\"),  # Replace with your Azure deployment name\n",
    "            api_version=azure_api_version or os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    "            temperature=temp or 0,\n",
    "            openai_api_key=api_key or os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "            azure_endpoint=azure_endpoint or os.getenv(\"AZURE_OPENAI_ENDPOINT\")  # Explicitly pass the endpoint\n",
    "        )\n",
    "\n",
    "    synthesis_prompt = f\"\"\"\n",
    "    You are a materials synthesis extraction assistant.\n",
    "\n",
    "    Your task is to read the synthesis procedure from a scientific paper and extract the full synthesis process for **each distinct material synthesized**. If multiple materials are synthesized, return a list of JSON objects, one for each material.\n",
    "\n",
    "    Only use information from the synthesis text provided in the Input section. If no synthesis information is present, return an empty list (`[]`).\n",
    "\n",
    "    Each material's synthesis should be structured as follows:\n",
    "\n",
    "    {{\n",
    "      \"material\": \"<exact formula or name as presented in the paper>\",\n",
    "      \"synthesis\": {{\n",
    "        \"steps\": [\n",
    "          {{\n",
    "            \"step\": 1,\n",
    "            \"label\": \"<Short title of the step, e.g., 'Precursor Mixing'>\",\n",
    "            \"details\": {{\n",
    "              \"reagents\": [\"<chemical names>\"],\n",
    "              \"temperature\": \"<value or null>\",\n",
    "              \"duration\": \"<value or null>\"\n",
    "            }}\n",
    "          }}\n",
    "        ]\n",
    "      }}\n",
    "    }}\n",
    "\n",
    "    ### Input:\n",
    "    {synthesis_text}\n",
    "\n",
    "    ### Output:\n",
    "    <Only return a list of structured JSON objects corresponding to each material synthesized, and nothing else>\n",
    "    \"\"\"\n",
    "    # Create a system message to set the context for the assistant\n",
    "    # and provide the synthesis prompt\n",
    "    # The system message is used to set the behavior and role of the assistant\n",
    "    # in the conversation. In this case, it is set to be a materials synthesis extraction assistant.\n",
    "    # The HumanMessage is the actual prompt that contains the synthesis text and instructions for extraction.\n",
    "    # The assistant will read the synthesis text and extract the synthesis procedure for each material.\n",
    "    # The assistant is expected to return a list of JSON objects, each containing the material name and its synthesis steps.\n",
    "    system_msg = SystemMessage(content=\"You are a materials synthesis extraction assistant.\")\n",
    "    \n",
    "    response = llm.invoke([\n",
    "    system_msg,\n",
    "    HumanMessage(content=synthesis_prompt)\n",
    "    ])\n",
    "    return response.content\n",
    "\n",
    "\n",
    "def extract_challenges(\n",
    "                       synthesis_text: str,\n",
    "                       api_key: str = None,  \n",
    "                       azure: bool = True, \n",
    "                       model_name: str = None, \n",
    "                       temp: float = 0, \n",
    "                       azure_api_version: str = None, \n",
    "                       azure_endpoint: str = None) -> str:\n",
    "    \"\"\"\n",
    "    Extract challenges information from a given text.\n",
    "\n",
    "    Parameters:\n",
    "        synthesis_text (str): The text containing challenges information.\n",
    "        api_key (str): OpenAI API key.\n",
    "        azure (bool): Flag to indicate if Azure OpenAI service should be used.\n",
    "        model_name (str, optional): The name of the Azure deployment or openai model name. Defaults to None.\n",
    "        temp (float, optional): The temperature for the model. Defaults to 0.   \n",
    "        azure_api_version (str, optional): The API version for Azure OpenAI service. Defaults to None.\n",
    "        azure_endpoint (str, optional): The endpoint for Azure OpenAI service. Defaults to None.\n",
    "        azure_api_version (str): The API version for Azure OpenAI service. Defaults to None.\n",
    "        \n",
    "    Returns:\n",
    "        str: JSON string containing the extracted challenges.\n",
    "    \"\"\"\n",
    "    if not azure:\n",
    "        llm = ChatOpenAI(model_name=model_name or os.getenv(\"OPENAI_MODEL_NAME\"),  # Replace with your OpenAI model name\n",
    "                         temperature=temp, \n",
    "                         openai_api_key=api_key or os.getenv(\"OPENAI_API_KEY\"))\n",
    "    else:\n",
    "        llm = AzureChatOpenAI(\n",
    "            azure_deployment=model_name or os.getenv(\"AZURE_MODEL_DEPLOYMENT_NAME\"),  # Replace with your Azure deployment name\n",
    "            api_version=azure_api_version or os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    "            temperature=temp or 0,\n",
    "            openai_api_key=api_key or os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "            azure_endpoint=azure_endpoint or os.getenv(\"AZURE_OPENAI_ENDPOINT\")  # Explicitly pass the endpoint\n",
    "        )\n",
    "\n",
    "    challenges_prompt = f\"\"\"\n",
    "\n",
    "    Your task is to carefully read the provided text about the synthesis, characterization, testing, and application of one or more materials. For each material discussed, identify any key **challenges** encountered during the research and the corresponding **solutions** the authors proposed or used.\n",
    "\n",
    "    Only use information from the provided text. If no challenges are described for a material, do not include it in the output. If the text does not mention any challenges at all, return an empty list (`[]`).\n",
    "\n",
    "    Return the results as a list of JSON objects. Each object should represent a single challenge related to a specific material and follow this format:\n",
    "\n",
    "    [\n",
    "      {{\n",
    "        \"material\": \"<exact formula or name as presented in the paper>\",\n",
    "        \"stage\": \"Synthesis\" | \"Characterization\" | \"Testing\" | \"Post-processing\" | \"Application\",\n",
    "        \"challenge\": \"Describe the specific problem the authors encountered in a concise way.\",\n",
    "        \"impact\": \"Explain why this problem matters â€” what negative effect it has.\",\n",
    "        \"solution\": \"Summarize how the authors addressed or solved this challenge.\",\n",
    "        \"evidence\": \"Quote or summarize where in the paper this information is discussed (e.g., page numbers, figures, tables, or sections).\"\n",
    "      }}\n",
    "    ]\n",
    "\n",
    "    ### Input:\n",
    "    {synthesis_text}\n",
    "\n",
    "    ### Output:\n",
    "    Return ONLY the JSON list of dictionaries, and nothing else.\n",
    "    \"\"\"\n",
    "    system_msg = SystemMessage(content=\"You are a helpful and precise materials research analysis assistant.\")\n",
    "    response = llm.invoke([\n",
    "    system_msg,\n",
    "    HumanMessage(content=challenges_prompt)\n",
    "    ])\n",
    "    return response.content"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
