{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reference: https://python.langchain.com/v0.1/docs/use_cases/sql/large_db/**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens in this notebook:\n",
    "\n",
    "### **Table Model Definition**\n",
    "   - **`Table` Class**: This is a simple Pydantic model representing a SQL table. It has one attribute, `name`, which is a string and is described as \"Name of table in SQL database.\"\n",
    "     - This model is used in the extraction process to match relevant SQL tables based on the user's query.\n",
    "\n",
    "### **Helper Function - `get_tables`**\n",
    "   - **`get_tables`**: This function takes a list of `Table` objects (i.e., categories such as \"Music\" or \"Business\") and returns a list of corresponding SQL table names based on the category.\n",
    "     - For example, if the category is `\"Music\"`, the tables `\"Album\"`, `\"Artist\"`, `\"Genre\"`, etc., are added to the result.\n",
    "     - Similarly, for `\"Business\"`, the corresponding tables like `\"Customer\"`, `\"Employee\"`, etc., are included.\n",
    "\n",
    "### **Designing the agent for the large DB**\n",
    "\n",
    "- **Step 1: Initialize LLM (`sql_agent_llm`)**: The LLM is instantiated with a given model (e.g., `\"gpt-3.5-turbo\"`) and temperature. The temperature controls how creative/random the model's responses are.\n",
    "- **Step 2: Connect to the SQL Database (`db`)**: The connection to the Chinook SQLite database is established. The database URI is constructed using the `sqldb_directory` provided.\n",
    "- **Step 3: Define Category Chain (`category_chain`)**: The `category_chain_system` is defined, which is a string explaining the categories available (like \"Music\" and \"Business\"). This chain determines which SQL tables are relevant to the user query based on the category.\n",
    "- **Step 4: Chain Creation**:\n",
    "- **`category_chain`**: This uses the `create_extraction_chain_pydantic` function, which creates an extraction chain that identifies relevant SQL tables from the user's question using the `Table` Pydantic model and the LLM.\n",
    "- **`table_chain`**: A chain is formed by combining the output from `category_chain` with the `get_tables` function, so it maps categories to the actual SQL tables.\n",
    "- **Step 5: Query Chain (`query_chain`)**: This creates a SQL query chain using the LLM and the database (`self.db`). It takes the SQL tables and constructs a query.\n",
    "- **Step 6: Table Chain Input Handling**: The `\"question\"` key from the user input is mapped to the `\"input\"` key expected by the `table_chain`. This enables the chain to process user queries correctly.\n",
    "- **Step 7: Full Chain Construction**: Finally, the full chain (`full_chain`) is created by combining:\n",
    "1. **`RunnablePassthrough.assign`**: This sets up a step that assigns the `table_names_to_use` using the result of the `table_chain`.\n",
    "2. **`query_chain`**: Executes the SQL query once the relevant tables are identified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pyprojroot import here\n",
    "from typing import List\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pprint import pprint\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set the environment variables and load the LLM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "sql_agent_llm = ChatOpenAI(model=\"gpt-4\", temperature=0)\n",
    "table_extractor_llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "# llm = ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sqlite\n",
      "['Applications', 'Comments', 'Compositions', 'Melting Points']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"[(353, 10359, None, None, 'Decomposes at 1750 C'), (494, 10503, None, None, None), (569, 10579, None, None, None), (618, 10628, None, None, 'Transition to calcite at 520. Antacid'), (636, 10646, None, 'A new method of X-Ray crystal analysis', None), (667, 10677, None, None, None), (696, 10706, None, None, None), (738, 10750, None, None, None), (780, 10792, None, None, None), (784, 10796, None, None, None)]\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqldb_directory = here(\"data/ICDD-energy.db\")\n",
    "db = SQLDatabase.from_uri(f\"sqlite:///{sqldb_directory}\")\n",
    "print(db.dialect)\n",
    "print(db.get_usable_table_names())\n",
    "db.run(\"SELECT * FROM Comments LIMIT 10;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prepare the `Table` class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Table(BaseModel):\n",
    "    \"\"\"\n",
    "    Represents a table in the SQL database.\n",
    "\n",
    "    Attributes:\n",
    "        name (str): The name of the table in the SQL database.\n",
    "    \"\"\"\n",
    "    name: str = Field(description=\"Name of table in SQL database.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Strategy A:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applications\n",
      "Comments\n",
      "Compositions\n",
      "Melting Points\n"
     ]
    }
   ],
   "source": [
    "table_names = \"\\n\".join(db.get_usable_table_names())\n",
    "print(table_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Table(name='Compositions')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains.openai_tools import create_extraction_chain_pydantic\n",
    "\n",
    "system = f\"\"\"Return the names of ALL the SQL tables that MIGHT be relevant to the user question. \\\n",
    "The tables are:\n",
    "\n",
    "{table_names}\n",
    "\n",
    "Remember to include ALL POTENTIALLY RELEVANT tables, even if you're not sure that they're needed.\"\"\"\n",
    "table_chain = create_extraction_chain_pydantic(pydantic_schemas=Table, llm=table_extractor_llm, system_message=system)\n",
    "table_chain.invoke({\"input\": \"how many compositions are there in the database?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Strategy B:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Music:\n",
    "\n",
    "- \"Album\"\n",
    "- \"Artist\"\n",
    "- \"Genre\"\n",
    "- \"MediaType\"\n",
    "- \"Playlist\"\n",
    "- \"PlaylistTrack\"\n",
    "- \"Track\"\n",
    "\n",
    "Business:\n",
    "\n",
    "- \"Customer\"\n",
    "- \"Employee\"\n",
    "- \"Invoice\"\n",
    "- \"InvoiceLine\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Table(name='Comments'),\n",
       " Table(name='Compositions'),\n",
       " Table(name='Applications'),\n",
       " Table(name='Melting Points')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains.openai_tools import create_extraction_chain_pydantic\n",
    "\n",
    "system = f\"\"\"You will recieve a question.\n",
    "\n",
    "If the question is about **Compositions**, return **ALL** these tables:\n",
    "  - \"Compositions\"\n",
    "\n",
    "If the question is about **Applications**, return **ALL** these tables:\n",
    "  - \"Applications\"\n",
    "\n",
    "If the question is about **Melting Points**, return **ALL** these tables:\n",
    "  - \"Melting Points\"\n",
    "\n",
    "If the question is about anything other than **Compositions**, **Applications**, and **Melting Points**, return **ALL** these tables:\n",
    "  - \"Comments\"\n",
    "if you don't know, return all tables.\n",
    "The tables are:\n",
    " -\"Compositions\"\n",
    "-\"Applications\"\n",
    "-\"Melting Points\"\n",
    "-\"Comments\"\n",
    "Remember to include ALL POTENTIALLY RELEVANT tables, even if you're not sure that they're needed.\n",
    ".\"\"\"\n",
    "table_chain = create_extraction_chain_pydantic(pydantic_schemas=Table, llm=table_extractor_llm, system_message=system)\n",
    "table_chain.invoke({\"input\": \"where most articles have been sited in the database?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Strategy C:**\n",
    "\n",
    "- **Step 1: Define the category**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.openai_tools import create_extraction_chain_pydantic\n",
    "\n",
    "system = \"\"\"Return the names of the SQL tables that are relevant to the user question. \\\n",
    "The tables are:\n",
    "\n",
    "Compositions\n",
    "Applications\n",
    "Melting Points\n",
    "Comments\n",
    "Remember to include ALL POTENTIALLY RELEVANT tables, even if you're not sure that they're needed.\"\"\"\n",
    "category_chain = create_extraction_chain_pydantic(pydantic_schemas=Table, llm=table_extractor_llm, system_message=system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Table(name='Compositions'),\n",
       " Table(name='Applications'),\n",
       " Table(name='Melting Points'),\n",
       " Table(name='Comments')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_chain.invoke({\"input\": \"What is the most frequently cited composition in the database?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Step 2: Execute the python function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Compositions', 'Applications', 'Melting Points', 'Comments']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_tables(categories: List[Table]) -> List[str]:\n",
    "    \"\"\"Maps category names to corresponding SQL table names.\n",
    "\n",
    "    Args:\n",
    "        categories (List[Table]): A list of `Table` objects representing different categories.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: A list of SQL table names corresponding to the provided categories.\n",
    "    \"\"\"\n",
    "    tables = []\n",
    "    for category in categories:\n",
    "        if category.name == \"Compositions\":\n",
    "            tables.extend(\n",
    "                [\"Compositions\"]\n",
    "            )\n",
    "        elif category.name == \"Melting Points\":\n",
    "            tables.extend([\"Melting Points\"])\n",
    "        elif category.name == \"Applications\":\n",
    "            tables.extend([\"Applications\"])\n",
    "        else:\n",
    "            tables.extend([\"Comments\"])\n",
    "    return tables\n",
    "\n",
    "\n",
    "table_chain = category_chain | get_tables \n",
    "table_chain.invoke({\"input\": \"What is the most frequently cited composition in the database?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Final step:**\n",
    "\n",
    "**Attach the desired strategy to your SQL agent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.chains import create_sql_query_chain\n",
    "from operator import itemgetter\n",
    "\n",
    "query_chain = create_sql_query_chain(sql_agent_llm, db)\n",
    "# Convert \"question\" key to the \"input\" key expected by current table_chain.\n",
    "table_chain = {\"input\": itemgetter(\"question\")} | table_chain\n",
    "# Set table_names_to_use using table_chain.\n",
    "full_chain = RunnablePassthrough.assign(table_names_to_use=table_chain) | query_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test the agent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT DISTINCT \"Description\" FROM \"Applications\"\n"
     ]
    }
   ],
   "source": [
    "query = full_chain.invoke(\n",
    "    {\"question\": \"What are all unique application values in the database?\"}\n",
    ")\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[('Battery Material',), ('Intercalate',), ('Ionic Conductor',), ('Superconducting Material',), ('Superconducting Material (Superconductor Reaction Product)',), ('Superconducting Material (Conventional Superconductor)',), ('Superconducting Material (Superconductor Related Material)',), ('Superconducting Material (Superconductor Reaction Product, Superconductor Related Material)',), ('Superconducting Material (High Tc Superconductor)',), ('Superconducting Material (Superconductor Related Material, High Tc Superconductor)',), ('Superconducting Material (Conventional Superconductor, High Tc Superconductor)',), ('Superconducting Material (Conventional Superconductor, Superconductor Related Material)',)]\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.run(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prepare the tool (Don't run the following cell)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ChinookSQLAgent:\n",
    "#     \"\"\"\n",
    "#     A specialized SQL agent that interacts with the Chinook SQL database using an LLM (Large Language Model).\n",
    "\n",
    "#     The agent handles SQL queries by mapping user questions to relevant SQL tables based on categories like \"Music\"\n",
    "#     and \"Business\". It uses an extraction chain to determine relevant tables based on the question and then\n",
    "#     executes queries against the database using the appropriate tables.\n",
    "\n",
    "#     Attributes:\n",
    "#         sql_agent_llm (ChatOpenAI): The language model used for interpreting and interacting with the database.\n",
    "#         db (SQLDatabase): The SQL database object, representing the Chinook database.\n",
    "#         full_chain (Runnable): A chain of operations that maps user questions to SQL tables and executes queries.\n",
    "\n",
    "#     Methods:\n",
    "#         __init__: Initializes the agent by setting up the LLM, connecting to the SQL database, and creating query chains.\n",
    "\n",
    "#     Args:\n",
    "#         sqldb_directory (str): The directory where the Chinook SQLite database file is located.\n",
    "#         llm (str): The name of the LLM model to use (e.g., \"gpt-3.5-turbo\").\n",
    "#         llm_temperature (float): The temperature setting for the LLM, controlling the randomness of responses.\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(self, sqldb_directory: str, llm: str, llm_temerature: float) -> None:\n",
    "#         \"\"\"Initializes the ChinookSQLAgent with the LLM and database connection.\n",
    "\n",
    "#         Args:\n",
    "#             sqldb_directory (str): The directory path to the SQLite database file.\n",
    "#             llm (str): The LLM model identifier (e.g., \"gpt-3.5-turbo\").\n",
    "#             llm_temerature (float): The temperature value for the LLM, determining the randomness of the model's output.\n",
    "#         \"\"\"\n",
    "#         self.sql_agent_llm = ChatOpenAI(\n",
    "#             model=llm, temperature=llm_temerature)\n",
    "\n",
    "#         self.db = SQLDatabase.from_uri(f\"sqlite:///{sqldb_directory}\")\n",
    "#         print(self.db.get_usable_table_names())\n",
    "#         category_chain_system = \"\"\"Return the names of the SQL tables that are relevant to the user question. \\\n",
    "#         The tables are:\n",
    "\n",
    "#         Music\n",
    "#         Business\"\"\"\n",
    "#         category_chain = create_extraction_chain_pydantic(\n",
    "#             Table, self.sql_agent_llm, system_message=category_chain_system)\n",
    "#         table_chain = category_chain | get_tables  # noqa\n",
    "#         query_chain = create_sql_query_chain(self.sql_agent_llm, self.db)\n",
    "#         # Convert \"question\" key to the \"input\" key expected by current table_chain.\n",
    "#         table_chain = {\"input\": itemgetter(\"question\")} | table_chain\n",
    "#         # Set table_names_to_use using table_chain.\n",
    "#         self.full_chain = RunnablePassthrough.assign(\n",
    "#             table_names_to_use=table_chain) | query_chain\n",
    "\n",
    "\n",
    "# @tool\n",
    "# def query_chinook_sqldb(query: str) -> str:\n",
    "#     \"\"\"Query the Chinook SQL Database. Input should be a search query.\"\"\"\n",
    "#     # Create an instance of ChinookSQLAgent\n",
    "#     agent = ChinookSQLAgent(\n",
    "#         sqldb_directory=TOOLS_CFG.chinook_sqldb_directory,\n",
    "#         llm=TOOLS_CFG.chinook_sqlagent_llm,\n",
    "#         llm_temerature=TOOLS_CFG.chinook_sqlagent_llm_temperature\n",
    "#     )\n",
    "\n",
    "#     query = agent.full_chain.invoke({\"question\": query})\n",
    "\n",
    "#     return agent.db.run(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM-for-mater",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
